{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZnoRPmkp6lm9nQH9vzUf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Igwe-Ugo/Facial_recognition_system/blob/main/face_recog_resnet50_application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mediapipe opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIqgCeHxvvQt",
        "outputId": "7da3fa5d-5b95-493b-86b5-ed5740ed6086"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.0-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.15 protobuf-4.25.4 sounddevice-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4qx3Pb6nvQuq"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained face embedding model\n",
        "face_embedding_model = load_model('face_embedding_model.keras')"
      ],
      "metadata": {
        "id": "3-qyI3sAwAeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MediaPipe Face Detection\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)"
      ],
      "metadata": {
        "id": "DMsQZMihwAVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_face(face_img):\n",
        "    # Resize the face image to 224x224 pixels (required input size for the model)\n",
        "    face_img = cv2.resize(face_img, (224, 224))\n",
        "    # Convert the image from BGR to RGB color space\n",
        "    face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "    # Preprocess the image using ResNet50's preprocessing function\n",
        "    face_img = tf.keras.applications.resnet50.preprocess_input(face_img)\n",
        "    # Add a batch dimension to the image\n",
        "    return np.expand_dims(face_img, axis=0)"
      ],
      "metadata": {
        "id": "4nIqm2MuwAST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face_embedding(face_img):\n",
        "    # Preprocess the face image\n",
        "    preprocessed_face = preprocess_face(face_img)\n",
        "    # Generate the embedding using the pre-trained model\n",
        "    return face_embedding_model.predict(preprocessed_face)[0]"
      ],
      "metadata": {
        "id": "h1C8E86PwAO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_embeddings(emb1, emb2, threshold=0.5):\n",
        "    # Calculate the Euclidean distance between two embeddings\n",
        "    distance = np.linalg.norm(emb1 - emb2)\n",
        "    # Return True if the distance is below the threshold (faces match)\n",
        "    return distance < threshold"
      ],
      "metadata": {
        "id": "PyDQ2oYswALw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_face(frame, known_faces):\n",
        "    # Convert the frame from BGR to RGB color space\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Detect faces in the frame using MediaPipe\n",
        "    results = face_detection.process(rgb_frame)\n",
        "\n",
        "    if results.detections:\n",
        "        for detection in results.detections:\n",
        "            # Get the bounding box of the detected face\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            ih, iw, _ = frame.shape\n",
        "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
        "                         int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "\n",
        "            # Extract the face image from the frame\n",
        "            face_img = frame[y:y+h, x:x+w]\n",
        "            # Generate the embedding for the detected face\n",
        "            face_embedding = get_face_embedding(face_img)\n",
        "\n",
        "            recognized = False\n",
        "            # Compare the detected face with known faces\n",
        "            for name, known_embedding in known_faces.items():\n",
        "                if compare_embeddings(face_embedding, known_embedding):\n",
        "                    # If a match is found, label the face with the person's name\n",
        "                    cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "                    recognized = True\n",
        "                    break\n",
        "\n",
        "            if not recognized:\n",
        "                # If no match is found, label the face as \"Unknown\"\n",
        "                cv2.putText(frame, \"Unknown\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "            # Draw a rectangle around the detected face\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "OaRX9A05wAIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load known faces\n",
        "known_faces = {}\n",
        "known_faces_dir = \"known_faces\"\n",
        "for person in os.listdir(known_faces_dir):\n",
        "    person_dir = os.path.join(known_faces_dir, person)\n",
        "    if os.path.isdir(person_dir):\n",
        "        for img_name in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_name)\n",
        "            # Load the image of the known person\n",
        "            img = cv2.imread(img_path)\n",
        "            # Generate the embedding for the known face\n",
        "            face_embedding = get_face_embedding(img)\n",
        "            # Store the embedding with the person's name\n",
        "            known_faces[person] = face_embedding\n",
        "            break  # We only need one image per person"
      ],
      "metadata": {
        "id": "4Hr0NiYYwAFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start video capture\n",
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "uq9lNB7cwACM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    # Read a frame from the video capture\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process the frame to recognize faces\n",
        "    frame = recognize_face(frame, known_faces)\n",
        "\n",
        "    # Display the processed frame\n",
        "    cv2.imshow('Face Recognition', frame)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "9AhCdtekv_-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZEfzcISv_7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Owcsd_SCv_4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9aJkAb6Jv_1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOaX-K9Kv_xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjLhWojvv_uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZwyGoPav_q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXE1gu6cv_iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXxR7gHlv_CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skHGQ4oXvl9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}